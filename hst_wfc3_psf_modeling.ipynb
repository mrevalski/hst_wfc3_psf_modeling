{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HST WFC3 PSF Modeling\n",
    "\n",
    "**Author:** Mitchell Revalski\n",
    "\n",
    "**Updated:** August 11, 2021\n",
    "\n",
    "Copyright (c) 2021, Mitchell Revalski\n",
    "\n",
    "All rights reserved. This source code is licensed under the BSD-style license found in the LICENSE file in the root directory of this source tree.\n",
    "\n",
    "***\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This Jupyter Notebook was created by Dr. Mitchell Revalski to generate Point Spread Function (PSF) models for Hubble Space Telescope (HST) Wide Field Camera 3 (WFC3) data. The user may select from two types of PSF modeling methodologies depending on their science goals. The two modeling options are:\n",
    "\n",
    "**Stellar:** The code will generate a PSF model by stacking stars extracted from a drizzled science image. This requires a Source Extractor type catalog, or a list of (x,y) coordinates, that correspond to the stars the user would like to stack. The user may set a variety of selection criteria and manually exclude objects.\n",
    "\n",
    "**Empirical:** The code will generate a PSF model by stacking STScI PSFs from a drizzle created using Varun Bajaj's *wfc3tools* make_model_star_image(). This requires a list of PSF coordinates generated using make_model_star_image(), or a list of (x,y) coordinates corresponding to the model positions in the drizzle.\n",
    "\n",
    "See: [https://github.com/Vb2341/wfc3tools](https://github.com/Vb2341/wfc3tools)  and  [ISR WFC3 2016-12: Empirical Models for the WFC3/IR PSF - Jay Anderson - Mar 17, 2016](https://www.stsci.edu/files/live/sites/www/files/home/hst/instrumentation/wfc3/documentation/instrument-science-reports-isrs/_documents/2016/WFC3-2016-12.pdf)\n",
    "\n",
    "The second decision is for the user to select whether to create a PSF model of the entire image, or create independent PSF models of the inner and outer portions of their science image. This is useful for mosaics with a longer effective exposure time in the center and a shorter exposure time near the edges.\n",
    "\n",
    "Please send questions, comments, and suggestions to [Mitchell Revalski](https://www.mitchellrevalski.com). Thank you, and have a nice day!\n",
    "\n",
    "***\n",
    "\n",
    "## Software\n",
    "\n",
    "The Python environment used to run this notebook was built using conda:<br>\n",
    "<code>\n",
    "(base) ...:...$ conda create -n ac3 stsci\n",
    "</code>\n",
    "\n",
    "The jupyter notebook can then be run using the following call sequence:<br>\n",
    "<code>\n",
    "(base) ...:...$ conda activate ac3\n",
    "(ac3)  ...:...$ jupyter notebook\n",
    "</code>\n",
    "\n",
    "The critical package versions that the code was tested with include:<br>\n",
    "<code>\n",
    "python -> 3.7.4\n",
    "matplotlib -> 3.1.1\n",
    "numpy -> 1.17.\n",
    "scipy -> 1.3.1\n",
    "astropy -> 3.2.1\n",
    "photutils -> 0.7\n",
    "</code>    \n",
    "\n",
    "***\n",
    "\n",
    "## Table of Contents <a class=\"anchor\" id=\"tag0\"><a>\n",
    "\n",
    "\n",
    "**&emsp; 1) [Setup Options: Inputs/Outputs](#setup)<br>**\n",
    "**&emsp; 2) [Setup Options: Filter/PSF Type](#setup2)<br>**\n",
    "**&emsp; 3) [Setup Options: Model Fitting](#setup3)<br>**\n",
    "**&emsp; 4) [Setup Options: PSF Positions](#setup4)<br>**\n",
    "**&emsp; 5) [Setup Options: Source Extractor](#setup5)<br>**\n",
    "**&emsp; 6) [Setup Options: Manual Selection](#setup6)<br>**\n",
    "**&emsp; 7) [Start of Main Code](#start)<br>**\n",
    "**&emsp; 8) [Identify Stars in Image](#select)<br>**\n",
    "**&emsp; 9) [Select the Best Stars](#clean)<br>**\n",
    "**&ensp; 10) [Import Science Drizzle](#import)<br>**\n",
    "**&ensp; 11) [Import Empirical Drizzle](#import2)<br>**\n",
    "**&ensp; 12) [Extract Subimages](#extract)<br>**\n",
    "**&ensp; 13) [Define Median Function](#meanfunction)<br>**\n",
    "**&ensp; 14) [Define Fitting Function](#fitfunction)<br>**\n",
    "**&ensp; 15) [Image Interpolation](#interpolate)<br>**\n",
    "**&ensp; 16) [Image Profile Fitting](#fitting)<br>**\n",
    "**&ensp; 17) [Calculate Image Shifts](#shifts)<br>**\n",
    "**&ensp; 18) [Align the Images](#align)<br>**\n",
    "**&ensp; 19) [Median Image Stack](#combine)<br>**\n",
    "**&ensp; 20) [Reinterpolate Stack](#reinterpolate)<br>**\n",
    "**&ensp; 21) [Flux Conservation](#check)<br>**\n",
    "**&ensp; 22) [Measure PSF FWHM](#fwhm)<br>**\n",
    "**&ensp; 23) [Trouble Shooting](#trouble)<br>**\n",
    "**&ensp; 24) [Developer Notes](#developer)<br>**\n",
    "    \n",
    "***\n",
    "    \n",
    "## Imports\n",
    "\n",
    "The following packages are required to run the Jupyter Notebook:\n",
    " - *os* - change and make directories\n",
    " - *sys* - set paths to external codes\n",
    " - *matplotlib.pyplot* - create graphics\n",
    " - *numpy* - math and array functions\n",
    "      - *unravel_index* - find peak location\n",
    " - *operator* - greater and less than functions\n",
    " - *scipy* - image interpolation and shifting\n",
    "      - *interpolate.interp2d* - interpolate arrays\n",
    "      - *ndimage* - shift interpolated arrays\n",
    " - *astropy* - model fitting and file handling\n",
    "      - *io.fits* - import FITS files\n",
    "      - *modeling.models* - Gaussian and Moffat models\n",
    "      - *modeling.fitting* - fitting methods for models\n",
    " - *photutils* - peak finder for empirical modeling\n",
    "      - *detection.find_peaks* - find peaks in *wfc3tools* drizzle\n",
    " - *itertools* - iteration tools for loops       \n",
    "      - *chain* - separate concatenated lists in parallel mode\n",
    " - *multiprocessing* - allows for models to be fit using parallel mode\n",
    "      - *pool* - parallel processing manager that parses jobs\n",
    " - *fit_profile_parallel* - same as internally defined *fit_profile()* for parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The external function packages are documented at the following links:\n",
    "\n",
    "[https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp2d.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp2d.html)\n",
    "\n",
    "[https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.shift.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.shift.html)\n",
    "\n",
    "[https://docs.astropy.org/en/stable/api/astropy.modeling.functional_models.Gaussian2D.html](https://docs.astropy.org/en/stable/api/astropy.modeling.functional_models.Gaussian2D.html)\n",
    "\n",
    "[https://docs.astropy.org/en/stable/api/astropy.modeling.functional_models.Moffat2D.html](https://docs.astropy.org/en/stable/api/astropy.modeling.functional_models.Moffat2D.html)\n",
    "\n",
    "[https://photutils.readthedocs.io/en/stable/api/photutils.detection.find_peaks.html#photutils.detection.find_peaks](https://photutils.readthedocs.io/en/stable/api/photutils.detection.find_peaks.html#photutils.detection.find_peaks)\n",
    "\n",
    "[https://docs.python.org/3/library/itertools.html](https://docs.python.org/3/library/itertools.html)\n",
    "\n",
    "[https://docs.python.org/3/library/multiprocessing.html](https://docs.python.org/3/library/multiprocessing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "from numpy import unravel_index\n",
    "import operator\n",
    "import scipy\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy import ndimage\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models\n",
    "from astropy.modeling import fitting\n",
    "from photutils import find_peaks\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Options: Inputs/Outputs  <a class=\"anchor\" id=\"setup\"><a>\n",
    "[Table of Contents](#tag0)\n",
    "    \n",
    "***\n",
    "\n",
    "**The user is REQUIRED to specify the following:**\n",
    " - <font color=blue>*main_directory*</font> - directory where the code is located.\n",
    " \n",
    " \n",
    " - <font color=blue>*export_name*</font> - the prefix for exported files (only used if *export_results = True*).\n",
    " \n",
    " \n",
    " - <font color=blue>*export_results*</font> - True or False.\n",
    "      - True: the code will export the PSF models as FITS files.\n",
    "      - False: the code will run but not output any model files.\n",
    " \n",
    " \n",
    " - <font color=blue>*speak*</font> - True or False.\n",
    "      - True: the code will verbally report when 1) interpolation, 2) profile fitting, and 3) modeling are complete.\n",
    "      - False: the code will run silently.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*print_fit*</font> - True or False.\n",
    "      - True: the code will print detailed information about the model fits.\n",
    "      - False: the code will only print error messages about the model fits.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*parallel_mode*</font> - True or False (only used if *use_peaks = False*).\n",
    "      - True: the code will run faster by fitting models in parallel (recommended).\n",
    "      - False: the code will complete the model fits one at a time.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*number_of_cores*</font> - number of computer cores to employ (only used if *parallel_mode = True*).\n",
    "      - Value: the integer number of cores to utilize (e.g. 2, 4, 6... recommend half of total cores).\n",
    "      - 'max': the code will determine the number of computer cores available and use them all.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/Users/path/to/code/'\n",
    "\n",
    "export_name = 'hst_f140w_psf' # Name based on your filter.\n",
    "\n",
    "export_results = True\n",
    "\n",
    "speak = True\n",
    "\n",
    "print_fit = False\n",
    "\n",
    "parallel_mode = True\n",
    "\n",
    "number_of_cores = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Options: Filter/PSF Type  <a class=\"anchor\" id=\"setup2\"><a>\n",
    "[Table of Contents](#tag0)\n",
    "    \n",
    "***\n",
    "\n",
    "**The user is REQUIRED to specify the following:**\n",
    " - <font color=blue>*my_filter*</font> - filter of your science image (string, e.g. 'f125w', 'f140w', 'f336w').\n",
    " \n",
    " \n",
    " - <font color=blue>*science_drizzle*</font> - filename of your science image (string, expects build=False for drizzles, should handle both cases).\n",
    "    \n",
    "    \n",
    " - <font color=blue>*export_directory*</font> - the folder within *../my_filter/results/* where the data products will be saved (string).    \n",
    "    \n",
    " \n",
    " - <font color=blue>*rpix*</font> - the half-width dimension of the desired PSF model in pixels (e.g. *rpix* = 34 for a 68x68 pixel model and *rpix* = 34.5 for a 69x69 pixel model).\n",
    " \n",
    " \n",
    " - <font color=blue>*psf_type*</font> - 'stellar' or 'empirical'.\n",
    "      - 'stellar': assumes the *science_drizzle* is the ouput of the astrodrizzle software.    \n",
    "      - 'empirical': assumes the *science_drizzle* is the output of Varun Bajaj's *wfc3tools*.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*dual_psf*</font> - True or False.\n",
    "      - True: the code will calculate a PSF model for either the 'inner' or 'outer' regions of an image as defined by the *radius_switch* command.\n",
    "           - Useful for drizzles with long exposure center and short exposure edges to create independent PSF models.\n",
    "      - False: the code will calculate a single PSF model for the entire image.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*radius_switch*</font> - options are 'inner' or 'outer' (string, only used if *dual_psf = True*).\n",
    "      - 'inner': PSF model is calculated using stars INSIDE a circle of radius *rmax*.\n",
    "      - 'outer': PSF model is calculated using stars OUTSIDE a circle of radius *rmax*.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*rmax*</font> - radius of a circle (in pixels) that delineates the 'inner' and 'outer' regions of the image.\n",
    "\n",
    "      \n",
    "A visual description of the *dual_psf*, *radius_switch*, and *rmax* options are shown below:\n",
    "![image](docs/dual_psf.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = 'f140w'\n",
    "\n",
    "science_drizzle = 'hst_f140w_drz_sci.fits'\n",
    "\n",
    "export_directory = 'v01'\n",
    "\n",
    "rpix = 34.5\n",
    "\n",
    "psf_type = 'stellar'\n",
    "\n",
    "#psf_type = 'empirical'\n",
    "\n",
    "dual_psf = True\n",
    "\n",
    "#dual_psf = False\n",
    "\n",
    "radius_switch = 'inner'\n",
    "\n",
    "#radius_switch = 'outer'\n",
    "\n",
    "rmax = 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell determines whether your PSF is even or odd in size and fixes the center pixel location for your PSF model. These lines should only be modified in special cases where an off-centered PSF model is desired or if your model is not centered based on the conventions of your next analysis codes (e.g. indices starting at 0 versus 1). By default the offsets are programmed for SAO DS9 image coordinates: [https://sites.google.com/cfa.harvard.edu/saoimageds9](https://sites.google.com/cfa.harvard.edu/saoimageds9). The user-supplied value of *rpix* is converted to an integer in order to work in array space and extract postage-stamps of the objects. The actual decimal value will be used later to set the size of the PSF model and is encapsulated in the *new_center* and *subimg_shape* variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rpix % 2 == 0:\n",
    "    subimg_shape = 'even'\n",
    "    new_center = rpix\n",
    "else:\n",
    "    subimg_shape = 'odd'\n",
    "    new_center = rpix-1.0\n",
    "    \n",
    "rpix = numpy.int(numpy.floor(rpix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Options: Model Fitting  <a class=\"anchor\" id=\"setup3\"><a>\n",
    "[Table of Contents](#tag0)\n",
    "    \n",
    "***\n",
    "\n",
    "**The user is REQUIRED to specify the following:**\n",
    " - <font color=blue>*interp_grid_steps*</font> - the interpolation grid resolution (e.g. 10 = 0.1 pixel interpolation scale).\n",
    "      - Use only even numbers, recommend a value of 2 for testing and 10 or 20 for final results.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*fit_type*</font> - 'gaussian' or 'moffat'.\n",
    "      - 'gaussian': the code will fit a Gaussian profile to each object.\n",
    "      - 'moffat': the code will fit a Moffat profile to each object.\n",
    "           - A Moffat profile is recommended for fitting stars due to their extended wings.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*max_iterations*</font> - the maximum number of convergence iterations for the fitting routine.\n",
    "      - Do NOT set below 100, recommend 2,000+ for IR images and 150,000+ for UVIS images.\n",
    "      - If the code reports a possible issue with fitting, then increase the number of *max_iterations*.      \n",
    "\n",
    "\n",
    " - <font color=blue>*scale_stars*</font> - True or False.\n",
    "      - True: The flux of each star or model will be scaled to unity before stacking (strongly recommended for stars).\n",
    "      - False: The flux of each model or star is unaltered and will be mean/median combined (special cases).\n",
    " \n",
    " \n",
    " - <font color=blue>*scale_image*</font> - True or False.\n",
    "      - True: The total area of the final PSF model will be scaled to unity (strongly recommended).\n",
    "      - False: The total area of the final PSF model is unaltered after mean and median combining (special cases).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_grid_steps = 20.\n",
    "\n",
    "fit_type = 'moffat'\n",
    "\n",
    "max_iterations = 200000\n",
    "\n",
    "scale_stars = True\n",
    "\n",
    "scale_image = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Options: PSF Positions  <a class=\"anchor\" id=\"setup4\"><a>\n",
    "[Table of Contents](#tag0)\n",
    "    \n",
    "***\n",
    "\n",
    "**The user is REQUIRED to specify the following:**\n",
    " \n",
    " - <font color=blue>*read_positions*</font>   - True or False.\n",
    "      - True: the initial guess (x,y) coordinates of the PSF centroids will be read from an external text file (see *positions_file* below).\n",
    "          - This default feature is useful if you already know the approximate centroid locations, or want to use specific stars in an image.      \n",
    "      - False: the initial guess (x,y) coordinates will be found using a peak finding algorithm (see warning below).    \n",
    "          - This will select all peaks in the image, so is only recommended for *psf_type = 'empirical'*, where the image contains well-spaced and normalized point sources. To adjust the threshold settings of this function, go to [*peaks_table = find_peaks(...)*](#import2).\n",
    "    \n",
    "    \n",
    " - <font color=blue>*lock_positions*</font>   - True or False (only used if *read_positions = True*).\n",
    "      - True: this will override the codes fitting, and use the *exact* (x,y) centroid coordinates from the external file (<font color=red>not recommended</font>).\n",
    "          - This feature is useful if you already know the exact centroid locations, or for debugging.\n",
    "      - False: the (x,y) coordinates from the file are used as initial guesses by the fitting routine.\n",
    "          - This is the recommended default setting, which allows the code to fit Moffat or gaussian profiles to the sources.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*positions_file*</font>   - a catalog or file of the approximate object locations in the image (only used if *read_positions = True*).\n",
    "      - This file should contain the stellar or empirical PSF locations, typically a Source Extractor catalog or a two-column text file of (x,y) locations.\n",
    "          - The type of file is specified by the *use_source_catalog_xy_coords* and *use_list_of_manual_xy_coords* commands below.      \n",
    "      - If using Varun Bajaj's PSF drizzling tool, then this file may be generated by saving the output of the *generate_input_coordinates()* function.\n",
    "          - Only use this option with the output from *generate_input_coordinates()* if *lock_positions = False*, as the locations are not distortion corrected.\n",
    "      \n",
    "\n",
    " - <font color=blue>*use_peaks*</font>   - True or False.\n",
    "      - True: (x,y) coordinates of the PSF centroids are the locations of the peak fluxes.\n",
    "          - This command may be used when *read_positions* is True or False. It is particularly useful for symmetric PSFs in the UV, where the peak flux location, and the centroid from a Moffat fit profile, are very similar. In this case, the code runs much faster by simply using the peak value.      \n",
    "      - False: (x,y) coordinates of the PSF centroids will be fit using the profile specified by *fit_type*.\n",
    "          - This is the default, which allows the code to fit gaussian or Moffat profiles to the objects.\n",
    "\n",
    "<font color=red>Note that only one of the following two options should be set to True, the other MUST be False:</font>\n",
    "          \n",
    " - <font color=blue>*use_source_catalog_xy_coords*</font>   - True or False (only used if *read_positions = True*).\n",
    "      - True: the (x,y) coordinates of objects are expected to come from a Source Extractor catalog.\n",
    "          - Note: the catalog can be made by any tool, e.g. photutils, but must contain the Source Extractor equivalent measures of: ID, X, Y, class_star, mag_iso, and elongation. See the *source_extractor_catalog* variable below for a more detailed description.\n",
    "      \n",
    "      - False: set to False if not using a source catalog.     \n",
    "      \n",
    "          \n",
    " - <font color=blue>*use_list_of_manual_xy_coords*</font>   - True or False (only used if *read_positions = True*).\n",
    "      - True: the (x,y) coordinates of objects are expected to come from a simple two-column list.\n",
    "          - Note: the (x,y) pairs should be in image (pixel) coordinates, with one pair per line in a .txt file.\n",
    "      \n",
    "      - False: set to False if not using a simple two-column list.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_positions = True\n",
    "\n",
    "lock_positions = False\n",
    "\n",
    "positions_file = 'your_source_extractor_catalog.cat'\n",
    "\n",
    "use_peaks = False\n",
    "\n",
    "use_source_catalog_xy_coords = True # Read in Source Extractor catalog and select stars.\n",
    "\n",
    "use_list_of_manual_xy_coords = False # Read in a two-column list of approximate (x,y) star coordinates.\n",
    "\n",
    "if (use_source_catalog_xy_coords == True and use_list_of_manual_xy_coords == True):\n",
    "    \n",
    "    print('\\033[1mWARNING: use_source_catalog_xy_coords and use_list_of_manual_xy_coords are both set to True!\\033[0m')\n",
    "    print('The code can read in either a Source Extractor type catalog, or a two-column list of coordinates.')\n",
    "    print('Please set one of these options to false and run the above cell again to propagate your selection.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Options: Source Extractor  <a class=\"anchor\" id=\"setup5\"><a>\n",
    "[Table of Contents](#tag0)\n",
    "    \n",
    "***\n",
    "\n",
    "**The user is REQUIRED to specify the following ONLY if *psf_type = 'stellar'* AND *use_source_catalog_xy_coords = True*:**\n",
    " - <font color=blue>*source_extractor_catalog*</font> - the filename of your Source Extractor catalog (string, .cat format).\n",
    "      - MUST include columns for: ID (col 0), X (col 1), Y (col 2), class_star, mag_iso, and elongation.\n",
    "      - Note: the mag_iso parameter may be any Source Extractor magnitude measure.\n",
    "      \n",
    "\n",
    " - <font color=blue>*header_rows*</font> - the number of header rows contained in your catalog.\n",
    "      - Note: Python starts indices at zero so e.g. 52 rows is entered as 51.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*class_star_column*</font> - the catalog column number of the *class_star* parameter.   \n",
    "      - Note: Python starts indices at zero so e.g. column 1 is entered as 0.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*mag_iso_column*</font> - the catalog column number of the *mag_iso_column* parameter.     \n",
    "      - Note: Python starts indices at zero so e.g. column 2 is entered as 1.\n",
    "      \n",
    "      \n",
    " - <font color=blue>*elongation_column*</font> - the catalog column number of the *elongation_column* parameter.    \n",
    "      - Note: Python starts indices at zero so e.g. column 3 is entered as 2.     \n",
    "     \n",
    "\n",
    " - <font color=blue>*class_star_limit*</font> - threshold for a star to be included in the model.\n",
    "      - Range is 0 to 1 and recommend a setting of ~ 0.8 or greater.\n",
    "      - Setting this too low will select non-stellar objects and too high results in too few stars. \n",
    "      \n",
    " \n",
    " - <font color=blue>*elongation_limit*</font> - threshold for a star to be included in the model.\n",
    "      - Range is > 1 and recommend a setting of ~ 1.05 or greater (lower selects too few stars).\n",
    "      - Setting this too low will result in too few stars and too high results in selecting non-stellar objects.    \n",
    "      \n",
    "      \n",
    " - <font color=blue>*manual_exclude*</font> - True or False.\n",
    "      - True: Stars that are included in the manual exclusion lists below will be dropped.\n",
    "          - In general, run the stellar selection code cell once, identify low quality stars visually, and add them to the exclusion list for the next run.\n",
    "      - False: All stars automatically selected by the code will be used in the PSF model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_extractor_catalog = positions_file\n",
    "\n",
    "header_rows = 51\n",
    "\n",
    "class_star_column = 25\n",
    "\n",
    "mag_iso_column = 26\n",
    "\n",
    "elongation_column = 54\n",
    "\n",
    "class_star_limit = 0.84\n",
    "\n",
    "elongation_limit = 1.07\n",
    "\n",
    "manual_exclude = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Options: Manual Selection  <a class=\"anchor\" id=\"setup6\"><a>\n",
    "[Table of Contents](#tag0)\n",
    "    \n",
    "***\n",
    "\n",
    "**The user is REQUIRED to specify the following ONLY if *psf_type = 'stellar'* AND *manual_exclude = True*:**\n",
    "\n",
    "The following cell allows the user to manually set the minimum distance for neighboring objects (*dists_from_star_limit*) and iteratively select out poor-quality stars from those that are automatically selected by the code. Stars are excluded by specifying a list of Source Extractor IDs, as well as a minimum magnitude limit for faint stars.\n",
    "\n",
    "To guarantee that there are no contaminating objects, neighbors at distances of *dists_from_star_limit* < sqrt(2)\\*rpix should be excluded (or larger when the field contains many extended objects. However, this may exlcude too many stars so using the half-width of the PSF size (*rpix*) and then manually excluding contaminated objects may be more practical.\n",
    "\n",
    "In small and/or crowded fields, the *dists_from_star_limit* may be set to zero, as long as there are sufficient stars in the stack such that individual contaminating objects disappear in the median stack. There is no exact value for the minimum number of stars needed to \"median out\" contaminants, but > 5 may be considered a practical minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if manual_exclude == True:\n",
    "\n",
    "    if radius_switch == 'inner':\n",
    "        \n",
    "        dists_from_star_limit = numpy.int(1.0*rpix)\n",
    "        \n",
    "        if my_filter == 'f336w':\n",
    "            drop_stars = []\n",
    "            mag_iso_limit = 30.0      \n",
    "        \n",
    "        if my_filter == 'f125w':\n",
    "            drop_stars = []\n",
    "            mag_iso_limit = 30.0\n",
    "        \n",
    "        if my_filter == 'f140w':\n",
    "            drop_stars = []\n",
    "            mag_iso_limit = 30.0\n",
    "\n",
    "    if radius_switch == 'outer':\n",
    "        \n",
    "        dists_from_star_limit = numpy.int(1.0*rpix)\n",
    "        \n",
    "        if my_filter == 'f336w':\n",
    "            drop_stars = []\n",
    "            mag_iso_limit = 22.20        \n",
    "    \n",
    "        if my_filter == 'f125w':\n",
    "            drop_stars = []\n",
    "            mag_iso_limit = 22.20\n",
    "    \n",
    "        if my_filter == 'f140w':\n",
    "            drop_stars = []\n",
    "            mag_iso_limit = 22.20\n",
    "    \n",
    "if manual_exclude == False:\n",
    "    \n",
    "    drop_stars = [-1]\n",
    "\n",
    "    mag_iso_limit = 98.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## <font color=Green>Start of Main Code</font>\n",
    "##### No user inputs are required below this cell. <a class=\"anchor\" id=\"start\"><a>\n",
    "    \n",
    "***\n",
    "    \n",
    "## Create folders for the results\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories and build folder tree.\n",
    "\n",
    "os.chdir(main_directory)\n",
    "\n",
    "try:\n",
    "    os.mkdir(my_filter)\n",
    "except:\n",
    "    print('Directory already exists...')\n",
    "    \n",
    "code_directory = main_directory+my_filter+'/'\n",
    "\n",
    "\n",
    "os.chdir(code_directory)\n",
    "\n",
    "try:\n",
    "    os.mkdir('results')\n",
    "except:\n",
    "    print('Directory already exists...')\n",
    "    \n",
    "    \n",
    "os.chdir(code_directory+'/results/')\n",
    "\n",
    "try:\n",
    "    os.mkdir(export_directory)\n",
    "except:\n",
    "    print('Directory already exists...')\n",
    "    \n",
    "results_directory = code_directory+'results/'+export_directory+'/'\n",
    "\n",
    "\n",
    "os.chdir(results_directory)\n",
    "\n",
    "try:\n",
    "    os.mkdir(psf_type)\n",
    "except:\n",
    "    print('Directory already exists...')\n",
    "\n",
    "\n",
    "if dual_psf == True:\n",
    "    \n",
    "    dir1 = 'inner'\n",
    "    dir2 = 'outer'\n",
    "    \n",
    "    os.chdir(results_directory+psf_type+'/')\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(dir1)\n",
    "    except:\n",
    "        print('Directory already exists...')\n",
    "    try:\n",
    "        os.mkdir(dir2)\n",
    "    except:\n",
    "        print('Directory already exists...')\n",
    "\n",
    "\n",
    "if (dual_psf == True and radius_switch == 'inner'):\n",
    "    \n",
    "    dir_out = dir1+'/'\n",
    "\n",
    "if (dual_psf == True and radius_switch == 'outer'):\n",
    "    \n",
    "    dir_out = dir2+'/'\n",
    "    \n",
    "if dual_psf == False:\n",
    "    \n",
    "    dir1 = ''\n",
    "    dir2 = ''\n",
    "\n",
    "    \n",
    "print('\\nThe code_directory is:', code_directory)\n",
    "\n",
    "print('\\nThe results_directory is:', results_directory)\n",
    "\n",
    "os.chdir(code_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the coordinates for the center of the image.\n",
    "# This value may be set manually to offset the center and/or if the file header is incorrect.\n",
    "\n",
    "os.chdir(main_directory+my_filter)\n",
    "\n",
    "hdul = fits.open(science_drizzle)\n",
    "\n",
    "xcenter = (((hdul[0].header['NAXIS1']) / 2.0) + 1.0)\n",
    "\n",
    "ycenter = (((hdul[0].header['NAXIS2']) / 2.0) + 1.0)\n",
    "\n",
    "hdul.close()\n",
    "\n",
    "print('\\nThe calculated image center is located at (x,y) = ('+str(xcenter)+', '+str(ycenter)+').')\n",
    "print('\\nIf this is not the desired center then set the values manually in this cell.')\n",
    "\n",
    "#xcenter = \n",
    "\n",
    "#ycenter = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select stars from the users Source Extractor catalog <a class=\"anchor\" id=\"select\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (psf_type == 'stellar' and use_source_catalog_xy_coords == True):\n",
    "    \n",
    "    # Import the Source Extractor catalog.\n",
    "    catalog = numpy.loadtxt(fname=source_extractor_catalog, skiprows = header_rows)\n",
    "\n",
    "    # Extract the IDs and (x, y) coordinates from the 1st, 2nd and 3rd columns.\n",
    "    ids = catalog[:,0].astype(int)\n",
    "    xs = catalog[:,1]\n",
    "    ys = catalog[:,2]\n",
    "\n",
    "    # Extract class_star, mag_iso, and elongation for each object.\n",
    "    class_star = catalog[:,class_star_column]\n",
    "    mag_iso = catalog[:,mag_iso_column]\n",
    "    elongation = catalog[:,elongation_column]\n",
    "\n",
    "    # Calculate the distance of each source from the center of the field.\n",
    "    dists = numpy.sqrt((xs-xcenter)**2.0 + (ys-ycenter)**2.0)\n",
    "\n",
    "    print('There are', len(ids), 'entries in the catalog. \\n')\n",
    "    print(class_star)\n",
    "    print('The min and max class_star values are:', min(class_star), ',', max(class_star), '\\n')\n",
    "    print(mag_iso)\n",
    "    print('The min and max mag_iso values are:', min(mag_iso), ',', max(mag_iso), '\\n')\n",
    "    print(elongation)\n",
    "    print('The min and max elongation values are:', min(elongation), ',', max(elongation), '\\n')\n",
    "    print(numpy.around(dists, decimals=3))\n",
    "    print('The min and max dists values are: ~', int(min(dists)), 'and ~', int(max(dists)), 'pixels. \\n')\n",
    "\n",
    "    # Calculate the number of objects in each region.\n",
    "    print('The number of objects in the deep region is:', sum(i < rmax for i in dists))\n",
    "    print('The number of objects in the shal region is:', sum(i >= rmax for i in dists))\n",
    "    print('The total number of deep + shall objects is:', \n",
    "          sum(i < rmax for i in dists)+sum(dum >= rmax for dum in dists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify isolated stars based on neighbor, elongation, and magnitude limits <a class=\"anchor\" id=\"clean\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (psf_type == 'stellar' and use_source_catalog_xy_coords == True):\n",
    "    \n",
    "    # Search through all objects to locate isolated stars based on their class_star and distance from other objects.\n",
    "    stars_list = []\n",
    "\n",
    "    # Set search criteria to deep 'inner' or shallow 'outer' region.\n",
    "    if radius_switch == 'inner':\n",
    "        print('Searching for stars at < rmax (inner)...')\n",
    "\n",
    "    if radius_switch == 'outer':\n",
    "        print('Searching for stars at > rmax (outer)...')       \n",
    "\n",
    "    # Search over all objects in the catalog.\n",
    "    for j in range(len(ids)):\n",
    "    \n",
    "        # Set search criteria to deep 'inner' or shallow 'outer' region.\n",
    "        if radius_switch == 'inner':\n",
    "            gt_lt = operator.lt(dists[j], rmax)\n",
    "\n",
    "        if radius_switch == 'outer':\n",
    "            gt_lt = operator.gt(dists[j], rmax)\n",
    "    \n",
    "        if class_star[j] >= class_star_limit and gt_lt and elongation[j] <= elongation_limit\\\n",
    "        and ids[j] not in drop_stars and mag_iso[j] < mag_iso_limit:\n",
    "        \n",
    "            # Calculate the distance to all objects and determine if the star is isolated.\n",
    "            dists_from_star = numpy.sqrt((xs-xs[j])**2.0 + (ys-ys[j])**2.0)\n",
    "        \n",
    "            # Determine the closest neighbor, excluding the object itself.\n",
    "            closest_neighbor = min(dists_from_star[numpy.nonzero(dists_from_star)])\n",
    "        \n",
    "            # If the star is isolated then append it to the list.\n",
    "            if closest_neighbor >= dists_from_star_limit:\n",
    "            \n",
    "                stars_list.append(catalog[j])            \n",
    "                print('Star for PSF model: ID', ids[j], \n",
    "                      '- class_star =', class_star[j], \n",
    "                      '- closest =', int(closest_neighbor), 'pixels', \n",
    "                      '- elongation =', elongation[j], \n",
    "                      '- mag_iso =', mag_iso[j]) \n",
    "\n",
    "    # Print the IDs of the identified stars.\n",
    "    star_ids = [k[0] for k in stars_list]\n",
    "    print('\\nThe total number of stars is:', len(stars_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the science drizzle for stellar extraction <a class=\"anchor\" id=\"import\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (psf_type == 'stellar' and use_source_catalog_xy_coords == True):\n",
    "    \n",
    "    # Import the image mosaic for stellar extraction.\n",
    "    mosaic = fits.open(science_drizzle)\n",
    "    image = mosaic[0].data\n",
    "    mosaic.info()\n",
    "\n",
    "    # Extract the x and y coordinates of the stars.\n",
    "    xis = numpy.array([k[1] for k in stars_list])\n",
    "    yis = numpy.array([k[2] for k in stars_list])\n",
    "\n",
    "    print('\\n xis =', xis)\n",
    "    print('\\n yis =', yis)\n",
    "\n",
    "    # Determine the min, max, and mean offset error from rounding to integer pixel centers.\n",
    "    xoffsets = (xis - numpy.rint(xis))\n",
    "    xoffmean = numpy.around((numpy.mean(numpy.absolute(xoffsets))), decimals=3)\n",
    "    xoffsdev = numpy.around(numpy.std(numpy.absolute(xoffsets)), decimals=3)\n",
    "    xoffmin = numpy.around(numpy.amin(numpy.absolute(xoffsets)), decimals=3)\n",
    "    xoffmax = numpy.around(numpy.amax(numpy.absolute(xoffsets)), decimals=3)\n",
    "\n",
    "    yoffsets = (yis - numpy.rint(yis))\n",
    "    yoffmean = numpy.around((numpy.mean(numpy.absolute(yoffsets))), decimals=3)\n",
    "    yoffsdev = numpy.around(numpy.std(numpy.absolute(yoffsets)), decimals=3)\n",
    "    yoffmin = numpy.around(numpy.amin(numpy.absolute(yoffsets)), decimals=3)\n",
    "    yoffmax = numpy.around(numpy.amax(numpy.absolute(yoffsets)), decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the empirical drizzle for model extraction <a class=\"anchor\" id=\"import2\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if psf_type == 'empirical':\n",
    "    \n",
    "    os.chdir(code_directory)\n",
    "    \n",
    "    # Set the PSF model drizzle filename fixed by make_model_star_image().\n",
    "    psf_drizzle = science_drizzle.split('_sci', 1)[0]+'.fits'\n",
    "\n",
    "    # Import the image mosaic for extraction.\n",
    "    mosaic = fits.open(psf_drizzle)\n",
    "    image = mosaic[1].data\n",
    "    mosaic.info()    \n",
    "    \n",
    "    # Initialize arrays.\n",
    "    xis_all = []\n",
    "    yis_all = []\n",
    "    xis = []\n",
    "    yis = []\n",
    "    psf_ids_all = []    \n",
    "    psf_ids = []\n",
    "    \n",
    "    \n",
    "    if use_list_of_manual_xy_coords == True:\n",
    "        \n",
    "        print('Reading PSF locations from', positions_file+'...\\n')\n",
    "    \n",
    "        my_input_coordinates = numpy.loadtxt(positions_file)\n",
    "\n",
    "        xis_all = my_input_coordinates[:,0]\n",
    "\n",
    "        yis_all = my_input_coordinates[:,1]\n",
    "\n",
    "        psf_ids_all = numpy.arange(0, len(my_input_coordinates), 1)  \n",
    "    \n",
    "    \n",
    "    if read_positions == False:\n",
    "    \n",
    "        # See: https://photutils.readthedocs.io/en/stable/detection.html\n",
    "        # photutils.detection.find_peaks(data, threshold, box_size=3, footprint=None, mask=None, \n",
    "        # border_width=None, npeaks=inf, centroid_func=None, subpixel=False, error=None, wcs=None)\n",
    "    \n",
    "        print('\\nSearching for PSFs in the drizzle...\\n')\n",
    "    \n",
    "        peaks_table = find_peaks(image, threshold=0.01, box_size=10.0)\n",
    "    \n",
    "        peaks_table['peak_value'].info.format = '%.6g'\n",
    "    \n",
    "        print('peak_finder has located', len(peaks_table), 'PSFs.\\n')\n",
    "    \n",
    "        print(peaks_table, '\\n')\n",
    "    \n",
    "        xis_all = peaks_table['x_peak']\n",
    "    \n",
    "        yis_all = peaks_table['y_peak']\n",
    "    \n",
    "        psf_ids_all = numpy.arange(0, len(peaks_table), 1)\n",
    "\n",
    "        \n",
    "    # Search through all PSFs to locate those based on rmax criteria.\n",
    "    if dual_psf == True:\n",
    "        \n",
    "        # Calculate the distance of each PSF from the center of the field.\n",
    "        dists = numpy.sqrt((xis_all-xcenter)**2.0 + (yis_all-ycenter)**2.0)\n",
    "\n",
    "        # Set search criteria to deep 'inner' or shallow 'outer' region.\n",
    "        if radius_switch == 'inner':\n",
    "            print('Searching for PSFs at < rmax (inner)...')\n",
    "\n",
    "        if radius_switch == 'outer':\n",
    "            print('Searching for PSFs at > rmax (outer)...')       \n",
    "\n",
    "        # Search over all PSFs in the image.\n",
    "        for j in range(len(psf_ids_all)):\n",
    "    \n",
    "            # Set search criteria to deep 'inner' or shallow 'outer' region.\n",
    "            if radius_switch == 'inner':\n",
    "                gt_lt = operator.lt(dists[j], rmax)\n",
    "\n",
    "            if radius_switch == 'outer':\n",
    "                gt_lt = operator.gt(dists[j], rmax)\n",
    "    \n",
    "            # If the object is inside the circle then append its location.\n",
    "            if gt_lt:\n",
    "                xis.append(xis_all[j])\n",
    "                yis.append(yis_all[j])\n",
    "                psf_ids.append(psf_ids_all[j])\n",
    "\n",
    "    # If modeling the entire image then keep all objects.\n",
    "    if dual_psf == False:\n",
    "        \n",
    "        psf_ids = psf_ids_all\n",
    "        xis = xis_all\n",
    "        yis = yis_all\n",
    "\n",
    "    # Print the IDs of the identified PSFs.\n",
    "    print('\\nThe PSF IDs are:', psf_ids)\n",
    "    print('\\nThe total number of PSFs is:', len(psf_ids))\n",
    "    \n",
    "    # Pass the PSF IDs to the star_ids variable for compatibility with all functions.\n",
    "    star_ids = psf_ids  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract subimages of each object that will be stacked <a class=\"anchor\" id=\"extract\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract a subimage centered on the star.\n",
    "image_array = []\n",
    "\n",
    "for i in range(len(xis)):\n",
    "    \n",
    "    # Convert to integer and round to nearest value.\n",
    "    xi = int(numpy.rint(xis[i]))\n",
    "    yi = int(numpy.rint(yis[i]))\n",
    "    star_id = star_ids[i]\n",
    "    \n",
    "    # Print the x, y coordinates and extract each star image.\n",
    "    print('Star ID ' + str(int(star_id)) + ':'  + ' (x,y) = (' + str(xi) + ', ' + str(yi) + ')')\n",
    "    \n",
    "    # Python switches the \"slow\" axis so reverse x and y.\n",
    "    if subimg_shape == 'even':\n",
    "        subimage = image[yi-rpix:yi+rpix, xi-rpix:xi+rpix]\n",
    "    if subimg_shape == 'odd':\n",
    "        subimage = image[yi-rpix:yi+rpix+1, xi-rpix:xi+rpix+1]\n",
    "    \n",
    "    # Determine the location of the maximum flux.\n",
    "    peak_location = numpy.unravel_index(numpy.argmax(subimage, axis=None), subimage.shape)\n",
    "    print('The subimage peak flux (x,y) = (' + str(peak_location[1]) + ', ' + str(peak_location[0]) + ')')\n",
    "    \n",
    "    # Scale to maximum flux so all stars peak at unity.\n",
    "    if scale_stars == True:\n",
    "        print('Scaling the stars peak flux to unity...')\n",
    "        subimage = (subimage/numpy.amax(subimage))\n",
    "        \n",
    "    # Report extractions from peak_finder that do not contain a star.\n",
    "    if (peak_location[1] == 0 and peak_location[0] == 0):\n",
    "        \n",
    "        print('This object is outside the data region and will be excluded.\\n')\n",
    "    \n",
    "    # Protect against peak_finder results that don't have a star.\n",
    "    #if peak_location[1] != 0 and peak_location[0] != 0:\n",
    "    # Protect against peak_finder results that don't have a star and are near the edge.    \n",
    "    if (peak_location[1] != 0 and peak_location[0] != 0\\\n",
    "    and peak_location[1] > rpix/5.0 and peak_location[0] > rpix/5.0\\\n",
    "    and peak_location[1] < 1.8*rpix and peak_location[0] < 1.8*rpix):\n",
    "    \n",
    "        # Append subimage to image_array.\n",
    "        image_array.append(subimage)\n",
    "    \n",
    "        # Plot the resulting subimages.\n",
    "        figure, mysubplot = matplotlib.pyplot.subplots(1, 3, figsize=(11, 11))\n",
    "        mysubplot[0].imshow(subimage, cmap='gray', vmin=0.0, vmax=numpy.amax(subimage), origin='lower')\n",
    "        mysubplot[1].imshow(subimage, cmap='gray', vmin=0.0, vmax=numpy.amax(subimage)/10.0, origin='lower')\n",
    "        mysubplot[2].imshow(subimage, cmap='gray', vmin=0.0, vmax=numpy.amax(subimage)/100.0, origin='lower')\n",
    "        matplotlib.pyplot.tight_layout()\n",
    "        print('\\n            100% MAX:                       10% MAX:                       1% MAX:') \n",
    "        matplotlib.pyplot.show()\n",
    "        \n",
    "    else:\n",
    "        print('The peak flux is too close to the edge of the subimage.')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a recursive mean and median function <a class=\"anchor\" id=\"meanfunction\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mean and median function that can be called repetitively.\n",
    "# e.g. image_combine(input_array = image_array, export_file = export_name)\n",
    "\n",
    "def image_combine(input_array, export_file):\n",
    "    print('Creating a mean and median image stack...')\n",
    "\n",
    "    # Mean of star images.\n",
    "    mean_image = numpy.mean(input_array, axis=0)\n",
    "\n",
    "    # Median of star images.\n",
    "    median_image = numpy.median(input_array, axis=0)\n",
    "\n",
    "    # Scale the final images to have a total flux of unity.\n",
    "    if scale_image == True:\n",
    "        print('Scaling the stacks peak flux to unity...')\n",
    "        mean_image = (mean_image/numpy.sum(mean_image))\n",
    "        median_image = (median_image/numpy.sum(median_image))\n",
    "        extension = '_normalized.fits'\n",
    "\n",
    "    if scale_image == False:\n",
    "        extension = '.fits'\n",
    "    \n",
    "    mean_flux = numpy.sum(mean_image)\n",
    "    median_flux = numpy.sum(median_image)\n",
    "    \n",
    "    print('The mean_image total flux =', numpy.around(mean_flux, decimals=5))\n",
    "    print('The median_image total flux =', numpy.around(median_flux, decimals=5))\n",
    "    \n",
    "    # Plot the resulting subimages.\n",
    "    figure, mysubplot = matplotlib.pyplot.subplots(1, 3, figsize=(11, 11), sharex=True, sharey=True)\n",
    "    mysubplot[0].imshow(mean_image, cmap='gray', vmin=0.0, vmax=numpy.amax(mean_image), origin='lower')\n",
    "    mysubplot[1].imshow(mean_image, cmap='gray', vmin=0.0, vmax=numpy.amax(mean_image)/10.0, origin='lower')\n",
    "    mysubplot[2].imshow(mean_image, cmap='gray', vmin=0.0, vmax=numpy.amax(mean_image)/100.0, origin='lower')\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    print('\\nMean:        100% MAX:                      10% MAX:                       1% MAX:') \n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "    figure, mysubplot = matplotlib.pyplot.subplots(1, 3, figsize=(11, 11), sharex=True, sharey=True)\n",
    "    mysubplot[0].imshow(median_image, cmap='gray', vmin=0.0, vmax=numpy.amax(median_image), origin='lower')\n",
    "    mysubplot[1].imshow(median_image, cmap='gray', vmin=0.0, vmax=numpy.amax(median_image)/10.0, origin='lower')\n",
    "    mysubplot[2].imshow(median_image, cmap='gray', vmin=0.0, vmax=numpy.amax(median_image)/100.0, origin='lower')\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    print('\\nMedian:      100% MAX:                      10% MAX:                       1% MAX:') \n",
    "    matplotlib.pyplot.show()\n",
    "    \n",
    "    if (export_results == True and dual_psf == False):\n",
    "        my_psf = fits.PrimaryHDU(median_image)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+export_file+'_median'+extension, overwrite=True)\n",
    "        my_psf = fits.PrimaryHDU(mean_image)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+export_file+'_mean'+extension, overwrite=True)          \n",
    "        \n",
    "    if (export_results == True and dual_psf == True):\n",
    "        my_psf = fits.PrimaryHDU(median_image)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+dir_out+export_file+'_median'+extension, overwrite=True)\n",
    "        my_psf = fits.PrimaryHDU(mean_image)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+dir_out+export_file+'_mean'+extension, overwrite=True)\n",
    "    \n",
    "    # Return the mean and median images.\n",
    "    return mean_image, median_image\n",
    "    os.chdir(code_directory)\n",
    "    \n",
    "# End of function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a recursive profile fitting function <a class=\"anchor\" id=\"fitfunction\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data using either Gaussian2D or Moffat2D functions on the interpolated images.\n",
    "# e.g. fit_profile(model_type = 'gaussian/moffat', input_data = image_array, fit_info = True/False)\n",
    "\n",
    "def fit_profile(model_type, input_data, fit_info):\n",
    "\n",
    "    x_centroids = []\n",
    "    y_centroids = []\n",
    "\n",
    "    for i in range(len(input_data)):\n",
    "    \n",
    "        # Print the x, y coordinates and extract star image.\n",
    "        print('Star ID ' + str(int(star_ids[i])) + ':')\n",
    "    \n",
    "        # The data are the interpolated images.\n",
    "        data = input_data[i]\n",
    "    \n",
    "        # Create a finer grid of (x, y) coordinates for interpolation.\n",
    "        x_z = numpy.around(numpy.linspace(1, (2*rpix), num=2*interp_grid_steps*rpix, endpoint=True), decimals=5)\n",
    "        y_z = x_z\n",
    "    \n",
    "        # Declare the fitting algorithm.\n",
    "        fit_method = fitting.LevMarLSQFitter()\n",
    "        amplitude = numpy.max(data)\n",
    "    \n",
    "        # Declare the type of model to fit.\n",
    "        if model_type == 'gaussian':\n",
    "            fit_model = models.Gaussian2D(amplitude, x_mean=interp_grid_steps*rpix, y_mean=interp_grid_steps*rpix)\n",
    "        if model_type == 'moffat':\n",
    "            fit_model = models.Moffat2D(amplitude, x_0=interp_grid_steps*rpix, y_0=interp_grid_steps*rpix)\n",
    "        \n",
    "        # Generate the model array.            \n",
    "        ximg, yimg = numpy.indices(data.shape)\n",
    "    \n",
    "        # Fit the model to the data and evaluate.\n",
    "        fit_result = fit_method(fit_model, ximg, yimg, data, maxiter=max_iterations)\n",
    "        model = fit_result(ximg, yimg)\n",
    "        residual = (data - model) \n",
    "    \n",
    "        # Find the locations of the peak flux value in the data and model.\n",
    "        peak_location_data = numpy.unravel_index(numpy.argmax(data, axis=None), data.shape)\n",
    "        peak_location_model = numpy.unravel_index(numpy.argmax(model, axis=None), model.shape)\n",
    "    \n",
    "        peak_location_data_x = x_z[peak_location_data[1]]\n",
    "        peak_location_data_y = y_z[peak_location_data[0]]\n",
    "        peak_location_model_x = x_z[peak_location_model[1]]\n",
    "        peak_location_model_y = y_z[peak_location_model[0]]\n",
    "    \n",
    "        print('Peak Data Flux Indices  (y,x):', peak_location_data)\n",
    "        print('Peak Data Flux Center   (y,x):', peak_location_data_y, peak_location_data_x)\n",
    "        print('Peak Model Flux Indices (y,x):', peak_location_model)\n",
    "        print('Peak Model Flux Center  (y,x):', peak_location_model_y, peak_location_model_x)\n",
    "    \n",
    "        # Plot the data, model, and residuals side-by-side.\n",
    "        figure, mysubplot = matplotlib.pyplot.subplots(1, 3, figsize=(11, 11))\n",
    "        mysubplot[0].imshow(data, cmap='gray', vmin=0.0, vmax=numpy.amax(data)/100.0, origin='lower')\n",
    "        mysubplot[1].imshow(model, cmap='gray', vmin=0.0, vmax=numpy.amax(model)/100.0, origin='lower')\n",
    "        mysubplot[2].imshow(residual, cmap='gray', vmin=0.0, vmax=numpy.amax(residual)/100.0, origin='lower')\n",
    "        matplotlib.pyplot.tight_layout()\n",
    "        print('\\n              DATA:                          MODEL:                           RESIDUAL:') \n",
    "        matplotlib.pyplot.show()\n",
    "    \n",
    "        # Extract the model (x, y) centers.    \n",
    "        x_centroids.append(peak_location_model_x)    \n",
    "        y_centroids.append(peak_location_model_y)\n",
    "    \n",
    "        # Print detailed information of the fit if there is an error.\n",
    "        if fit_info == True:\n",
    "            print('fit_method.fit_info = ', fit_method.fit_info)\n",
    "    \n",
    "    # Announce completion.\n",
    "    if speak == True:\n",
    "        os.system(\"say 'fitting complete'\")\n",
    "        \n",
    "    # Return the lists of (x,y) centroids.\n",
    "    return x_centroids, y_centroids\n",
    "            \n",
    "# End of function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate each extracted subimage <a class=\"anchor\" id=\"interpolate\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The grid to interpolate is the same size as the original image.\n",
    "image_array_interpolated = []\n",
    "\n",
    "use_peaks_interp_x = []\n",
    "use_peaks_interp_y = []\n",
    "\n",
    "for i in range(len(image_array)):\n",
    "  \n",
    "    # Convert to integer and round to nearest value.\n",
    "    xi = int(numpy.rint(xis[i]))\n",
    "    yi = int(numpy.rint(yis[i]))\n",
    "    star_id = star_ids[i]\n",
    "    \n",
    "    # Print the x, y coordinates and extract each star image.\n",
    "    print('Star ID ' + str(int(star_id)) + ':'  + ' (x,y) = (' + str(xi) + ', ' + str(yi) + ')')\n",
    "    \n",
    "    # Python switches the \"slow\" axis so reverse x and y.\n",
    "    if subimg_shape == 'even':\n",
    "        \n",
    "        ximg = list(range(0, 2*rpix))\n",
    "        yimg = ximg\n",
    "        zimg = image[yi-rpix:yi+rpix, xi-rpix:xi+rpix]\n",
    "        \n",
    "        # Create a finer grid of (x, y) coordinates for interpolation.\n",
    "        x_z = numpy.around(numpy.linspace(1, (2*rpix), num=2*interp_grid_steps*rpix, endpoint=True), decimals=5)\n",
    "        y_z = x_z\n",
    "        \n",
    "    if subimg_shape == 'odd':\n",
    "            \n",
    "        ximg = list(range(0, (2*rpix)+1))\n",
    "        yimg = ximg\n",
    "        zimg = image[yi-rpix:yi+rpix+1, xi-rpix:xi+rpix+1]\n",
    "        \n",
    "        # Create a finer grid of (x, y) coordinates for interpolation.\n",
    "        x_z = numpy.around(numpy.linspace(1, ((2*rpix)+1), num=2*interp_grid_steps*rpix, endpoint=True), decimals=5)\n",
    "        y_z = x_z\n",
    "    \n",
    "    # Determine the location of the maximum flux.\n",
    "    peak_location = numpy.unravel_index(numpy.argmax(zimg, axis=None), zimg.shape)\n",
    "    print('The subimage peak flux (x,y) = (' + str(peak_location[1]) + ', ' + str(peak_location[0]) + ')')\n",
    "        \n",
    "    # Scale to maximum flux so all stars peak at unity.\n",
    "    if scale_stars == True:\n",
    "        print('Scaling the stars peak flux to unity...')\n",
    "        zimg = (zimg/numpy.amax(zimg))\n",
    "     \n",
    "    # Report extractions from peak_finder that do not contain a star.\n",
    "    if (peak_location[1] == 0 and peak_location[0] == 0):\n",
    "        \n",
    "        print('This object is outside the data region and will be excluded.\\n')\n",
    "    \n",
    "    # Protect against peak_finder results that don't have a star.\n",
    "    #if peak_location[1] != 0 and peak_location[0] != 0:\n",
    "    # Protect against peak_finder results that don't have a star and are near the edge.    \n",
    "    if (peak_location[1] != 0 and peak_location[0] != 0\\\n",
    "    and peak_location[1] > rpix/5.0 and peak_location[0] > rpix/5.0\\\n",
    "    and peak_location[1] < 1.8*rpix and peak_location[0] < 1.8*rpix):        \n",
    "    \n",
    "        # Interpolate to a finer grid.\n",
    "        f_z = scipy.interpolate.interp2d(ximg, yimg, zimg, kind='cubic')\n",
    "        \n",
    "        # Evaluate the interpolation function.\n",
    "        interpolated_image = f_z(x_z, y_z)\n",
    "    \n",
    "        # Append subimage to image_array.\n",
    "        image_array_interpolated.append(interpolated_image)\n",
    "    \n",
    "        # Save the interpolated peak (x,y) locations for use_peaks = True. #M.D.R 12/21/2020\n",
    "        if use_peaks == True:\n",
    "            peak_interp = numpy.unravel_index(numpy.argmax(interpolated_image, axis=None), interpolated_image.shape)\n",
    "            use_peaks_interp_x.append((peak_interp[1]/interpolated_image.shape[1])*(2*rpix)+0.5)\n",
    "            use_peaks_interp_y.append((peak_interp[0]/interpolated_image.shape[0])*(2*rpix)+0.5)        \n",
    "        \n",
    "        # Plot the data, model, and residuals side-by-side.\n",
    "        figure, mysubplot = matplotlib.pyplot.subplots(1, 2, figsize=(8, 8))\n",
    "        mysubplot[0].imshow(zimg, cmap='gray', vmin=0.0, vmax=numpy.amax(zimg)/100.0, origin='lower')\n",
    "        mysubplot[1].imshow(interpolated_image, cmap='gray', vmin=0.0, vmax=numpy.amax(interpolated_image)/100.0, origin='lower')\n",
    "        matplotlib.pyplot.tight_layout()\n",
    "        print('\\n              Original:                        Interpolated:') \n",
    "        matplotlib.pyplot.show()\n",
    "    \n",
    "# Announce completion.\n",
    "if speak == True:\n",
    "    os.system(\"say 'interpolation complete'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the fitting function on the interpolated images <a class=\"anchor\" id=\"fitting\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (parallel_mode == False and lock_positions == False and use_peaks == False):\n",
    "\n",
    "    # Call the fitting function.\n",
    "    my_centroids = fit_profile(model_type = fit_type, input_data = image_array_interpolated, fit_info = print_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (parallel_mode == False and lock_positions == False and use_peaks == False):\n",
    "    print(my_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (parallel_mode == True and lock_positions == False and use_peaks == False):\n",
    "\n",
    "    # fit_profile_parallel.py\n",
    "    import multiprocessing\n",
    "    \n",
    "    from multiprocessing import Pool\n",
    "    \n",
    "    from fit_profile_parallel import fit_profile_parallel\n",
    "    \n",
    "    if number_of_cores == 'max':\n",
    "        \n",
    "        number_of_cores = multiprocessing.cpu_count()\n",
    "        \n",
    "    print('Initializing parallel mode using', number_of_cores, 'cores.\\n')\n",
    "            \n",
    "    pool = Pool(number_of_cores)    \n",
    "\n",
    "    print('Beginning parallelized model fitting...\\n')\n",
    "    \n",
    "    print('There are', len(image_array_interpolated), 'profiles to fit.\\n')\n",
    "\n",
    "    input_data = image_array_interpolated\n",
    "    \n",
    "    pool_list = []\n",
    "    \n",
    "    j=0\n",
    "    \n",
    "    for i in input_data:\n",
    "        pool_list.append(('moffat', input_data[j], False, star_ids[j], rpix, interp_grid_steps, max_iterations, speak))\n",
    "        j=j+1\n",
    "        \n",
    "    print('Created a parallel list for', len(pool_list), 'objects.\\n')\n",
    "\n",
    "    my_centroids_parallel = pool.starmap(fit_profile_parallel, pool_list)\n",
    "\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (parallel_mode == True and lock_positions == False and use_peaks == False):\n",
    "    print(my_centroids_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (parallel_mode == True and lock_positions == False and use_peaks == False):\n",
    "\n",
    "    # Separate the concatenated (x,y) centroid lists produced by parallel_mode.\n",
    "    x_sep = [i[0] for i in my_centroids_parallel]\n",
    "    y_sep = [i[1] for i in my_centroids_parallel]\n",
    "\n",
    "    x_sep = list(chain.from_iterable(x_sep))\n",
    "    y_sep = list(chain.from_iterable(y_sep))\n",
    "\n",
    "    my_centroids_parallel_formatted = (x_sep, y_sep)\n",
    "                                  \n",
    "    print(my_centroids_parallel_formatted)\n",
    "    \n",
    "    # Test to ensure non-parallel and parallel runs produce identical ordered results.\n",
    "    #my_centroids == my_centroids_parallel_formatted\n",
    "\n",
    "    my_centroids = my_centroids_parallel_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the image shifts from the model fits <a class=\"anchor\" id=\"shifts\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (lock_positions == False and use_peaks == False):\n",
    "\n",
    "    # Determine the image shifts based on the model centers and the desired image center.\n",
    "    x_centroids = my_centroids[0]\n",
    "    y_centroids = my_centroids[1]\n",
    "\n",
    "    print('\\nx_centroids =', x_centroids)\n",
    "    print('\\ny_centroids =', y_centroids)\n",
    "\n",
    "    # Create a list filled with the desired center value.\n",
    "    my_center = []\n",
    "\n",
    "    for i in range(len(x_centroids)):\n",
    "        my_center.append(new_center)\n",
    "    print('\\nmy_center =', my_center)\n",
    "\n",
    "    # Calculate the (x, y) offsets.\n",
    "    xshifts = numpy.subtract(my_center, x_centroids)\n",
    "    yshifts = numpy.subtract(my_center, y_centroids)\n",
    "\n",
    "    print('\\nxshifts =', xshifts)\n",
    "    print('\\nyshifts =', yshifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if lock_positions == True:\n",
    "    \n",
    "    # Determine the image shifts based on the model centers and the desired image center.\n",
    "    x_centroids = xis\n",
    "    y_centroids = yis\n",
    "\n",
    "# Use the interpolated peak (x,y) locations if use_peaks = True.\n",
    "if use_peaks == True:\n",
    "\n",
    "    x_centroids = use_peaks_interp_x\n",
    "    y_centroids = use_peaks_interp_y\n",
    "\n",
    "    print('\\nx_centroids =', x_centroids)\n",
    "    print('\\ny_centroids =', y_centroids)\n",
    "\n",
    "    # Create a list filled with the desired center value.\n",
    "    my_center = []\n",
    "\n",
    "    for i in range(len(x_centroids)):\n",
    "        my_center.append(new_center)\n",
    "        if i==0: print('\\nmy_center = {}'.format(my_center))\n",
    "\n",
    "    # Calculate the (x, y) offsets.\n",
    "    xshifts = numpy.subtract(my_center, x_centroids)\n",
    "    yshifts = numpy.subtract(my_center, y_centroids)\n",
    "\n",
    "    # Make the offsets relative to the postage-stamps instead of the image.\n",
    "    # if use_peaks == False: # Confirm these shifts are correct in all cases.\n",
    "\n",
    "    #     xshifts = (xshifts + numpy.rint(x_centroids)) - new_center + 1.0\n",
    "    #     yshifts = (yshifts + numpy.rint(y_centroids)) - new_center + 1.0\n",
    "\n",
    "    print('\\nxshifts =', xshifts)\n",
    "    print('\\nyshifts =', yshifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align the interpolated images and calculate the median <a class=\"anchor\" id=\"align\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Determine shift recalling x and y are reversed in python manipulation.\n",
    "# See https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.shift.html for 'mode' choices.\n",
    "image_array_shifted = []\n",
    "\n",
    "# Zoom in factor for below plots.\n",
    "imgzoom = (1./interp_grid_steps)*6.0\n",
    "\n",
    "for i in range(len(xshifts)):\n",
    "    \n",
    "    #xshift > Positive = shift right. Negative = shift left.\n",
    "    #yshift > Positive = shift up. Negative = shift down.\n",
    "    \n",
    "    # Model fit values.\n",
    "    xshift = numpy.around(xshifts[i]*interp_grid_steps, decimals=5)\n",
    "    yshift = numpy.around(yshifts[i]*interp_grid_steps, decimals=5)\n",
    "    print('The Offsets (x, y) =', xshift, yshift)\n",
    "    \n",
    "    # Shift images by xshift and yshift.\n",
    "    shifted_image = scipy.ndimage.shift(image_array_interpolated[i], [yshift, xshift], mode='mirror')\n",
    "    \n",
    "    # Set approximate zoomed in center and subtract 0.5 for index axes.\n",
    "    xylimit = ((new_center-0.5)*interp_grid_steps)\n",
    "    \n",
    "    # Set imshow range to +/- some % of total.\n",
    "    xyrange = (xylimit/(imgzoom*interp_grid_steps))\n",
    "    \n",
    "    peak_original = numpy.unravel_index(numpy.argmax(image_array_interpolated[i], axis=None), image_array_interpolated[i].shape)\n",
    "    peak_original_x = peak_original[1]\n",
    "    peak_original_y = peak_original[0]\n",
    "    print('Before Shift: Peak Model Flux Center (x,y):', peak_original_x, peak_original_y)\n",
    "    \n",
    "    peak_shifted = numpy.unravel_index(numpy.argmax(shifted_image, axis=None), shifted_image.shape)\n",
    "    peak_shifted_x = peak_shifted[1]\n",
    "    peak_shifted_y = peak_shifted[0]\n",
    "    print('After Shift : Peak Model Flux Center (x,y):', peak_shifted_x, peak_shifted_y, '\\n')\n",
    "    \n",
    "    # Append subimage to image_array.\n",
    "    image_array_shifted.append(shifted_image)\n",
    "    \n",
    "    # Plot the data and shifted data side-by-side.\n",
    "    figure, mysubplot = matplotlib.pyplot.subplots(1, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "    matplotlib.pyplot.xlim(xylimit-xyrange, xylimit+xyrange)\n",
    "    matplotlib.pyplot.ylim(xylimit-xyrange, xylimit+xyrange)\n",
    "\n",
    "    mysubplot[0].imshow(image_array_interpolated[i], cmap='gray', vmin=0.0,\\\n",
    "                        vmax=numpy.amax(image_array_interpolated[i]), origin='lower')\n",
    "    mysubplot[0].scatter(xylimit, xylimit, s=1000000, c='green', marker='+')\n",
    "    mysubplot[0].scatter(peak_original_x, peak_original_y, s=300, c='black', marker='x')\n",
    "\n",
    "    mysubplot[1].imshow(shifted_image, cmap='gray', vmin=0.0,\\\n",
    "                        vmax=numpy.amax(shifted_image), origin='lower')    \n",
    "    mysubplot[1].scatter(xylimit, xylimit, s=1000000, c='green', marker='+')\n",
    "    mysubplot[1].scatter(peak_shifted_x, peak_shifted_y, s=300, c='black', marker='x')\n",
    "\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    print('                   Original:                                 Shifted:') \n",
    "    matplotlib.pyplot.show()\n",
    "    \n",
    "# The below images show the star before and after re-centering, where the \"x\" denotes the peak flux location.\n",
    "# The \"x\" will not be perfectly centered unless use_peaks = True, as the data and model peaks are slightly offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the mean and median image stack <a class=\"anchor\" id=\"combine\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the mean and median function. Save the output arrays for reinterpolation to the native pixel scale.\n",
    "mean_out, median_out = image_combine(input_array = image_array_shifted, \n",
    "                                     export_file = export_name+'_interpolated_'+fit_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinterpolate the stack to the native pixel scale <a class=\"anchor\" id=\"reinterpolate\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinterpolate the median and mean images to their original image scales.\n",
    "\n",
    "# Mean.\n",
    "zimg = mean_out\n",
    "# Evaluate the interpolation function to the original grid.\n",
    "f_z = scipy.interpolate.interp2d(x_z, y_z, zimg, kind='cubic')\n",
    "mean_reinterpolation = f_z(ximg, yimg)\n",
    "\n",
    "# Median.\n",
    "zimg = median_out\n",
    "# Evaluate the interpolation function to the original grid.\n",
    "f_z = scipy.interpolate.interp2d(x_z, y_z, zimg, kind='cubic')    \n",
    "median_reinterpolation = f_z(ximg, yimg)\n",
    "\n",
    "# Scale the final images to have a total flux of unity.\n",
    "if scale_image == True:\n",
    "    \n",
    "    mean_reinterpolation = (mean_reinterpolation/numpy.sum(mean_reinterpolation))\n",
    "    median_reinterpolation = (median_reinterpolation/numpy.sum(median_reinterpolation))\n",
    "\n",
    "# Calculate the total flux of each image.\n",
    "mean_flux_interp = numpy.sum(mean_reinterpolation)\n",
    "median_flux_interp = numpy.sum(median_reinterpolation)\n",
    "print('The mean_image total flux =', mean_flux_interp)\n",
    "print('The median_image total flux =', median_flux_interp)\n",
    "\n",
    "# Plot the resulting subimages.\n",
    "figure, mysubplot = matplotlib.pyplot.subplots(1, 3, figsize=(11, 11), sharex=True, sharey=True)\n",
    "mysubplot[0].imshow(mean_reinterpolation, cmap='gray', vmin=0.0, vmax=numpy.amax(mean_reinterpolation), origin='lower')\n",
    "mysubplot[1].imshow(mean_reinterpolation, cmap='gray', vmin=0.0, vmax=numpy.amax(mean_reinterpolation)/10.0, origin='lower')\n",
    "mysubplot[2].imshow(mean_reinterpolation, cmap='gray', vmin=0.0, vmax=numpy.amax(mean_reinterpolation)/100.0, origin='lower')\n",
    "matplotlib.pyplot.tight_layout()\n",
    "print('\\nMean:        100% MAX:                      10% MAX:                       1% MAX:') \n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "# Plot the resulting subimages.\n",
    "figure, mysubplot = matplotlib.pyplot.subplots(1, 3, figsize=(11, 11), sharex=True, sharey=True)\n",
    "mysubplot[0].imshow(median_reinterpolation, cmap='gray', vmin=0.0, vmax=numpy.amax(median_reinterpolation), origin='lower')\n",
    "mysubplot[1].imshow(median_reinterpolation, cmap='gray', vmin=0.0, vmax=numpy.amax(median_reinterpolation)/10.0, origin='lower')\n",
    "mysubplot[2].imshow(median_reinterpolation, cmap='gray', vmin=0.0, vmax=numpy.amax(median_reinterpolation)/100.0, origin='lower')\n",
    "matplotlib.pyplot.tight_layout()\n",
    "print('\\nMedian:      100% MAX:                      10% MAX:                       1% MAX:') \n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "# Set the directory for output files.\n",
    "if (dual_psf == True and radius_switch == 'inner'):\n",
    "    my_extension = dir1\n",
    "    \n",
    "if (dual_psf == True and radius_switch == 'outer'):\n",
    "    my_extension = dir2\n",
    "    \n",
    "if dual_psf == False:\n",
    "    my_extension = ''\n",
    "    \n",
    "\n",
    "# Export the images as DS9 readable .fits files.\n",
    "if export_results == True:\n",
    "    \n",
    "    if dual_psf == True:\n",
    "        my_psf = fits.PrimaryHDU(mean_reinterpolation)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+dir_out+export_name+'_'+psf_type+'_mean_'+my_extension+'.fits', overwrite=True)\n",
    "        my_psf = fits.PrimaryHDU(median_reinterpolation)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+dir_out+export_name+'_'+psf_type+'_median_'+my_extension+'.fits', overwrite=True)\n",
    "\n",
    "    elif dual_psf == False:\n",
    "        my_psf = fits.PrimaryHDU(mean_reinterpolation)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+export_name+'_'+psf_type+'_mean_'+my_extension+'.fits', overwrite=True)\n",
    "        my_psf = fits.PrimaryHDU(median_reinterpolation)\n",
    "        my_psf.writeto(results_directory+psf_type+'/'+export_name+'_'+psf_type+'_median_'+my_extension+'.fits', overwrite=True)    \n",
    "\n",
    "os.chdir(code_directory)\n",
    "\n",
    "# Announce completion.\n",
    "if speak == True:\n",
    "    os.system(\"say 'modeling complete'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm that flux was conserved <a class=\"anchor\" id=\"check\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that flux is conserved.\n",
    "mean_image = numpy.mean(image_array, axis=0)\n",
    "median_image = numpy.median(image_array, axis=0)\n",
    "\n",
    "# Scale the final images to have a total flux of unity.\n",
    "if scale_image == True:\n",
    "    mean_image = (mean_image/numpy.sum(mean_image))\n",
    "    median_image = (median_image/numpy.sum(median_image))\n",
    "\n",
    "mean_flux = numpy.sum(mean_image)\n",
    "median_flux = numpy.sum(median_image)\n",
    "\n",
    "# Compare to the fluxes of the interpolated images.\n",
    "avg = (mean_flux + mean_flux_interp)/2.0\n",
    "mean_percent_diff = (100.0*((mean_flux - mean_flux_interp)/avg))\n",
    "print('The mean   image percent difference in flux before and after interpolation:', mean_percent_diff, '%')\n",
    "\n",
    "avg = (median_flux + median_flux_interp)/2.0\n",
    "median_percent_diff = (100.0*((median_flux - median_flux_interp)/avg))\n",
    "print('The median image percent difference in flux before and after interpolation:', median_percent_diff, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the PSF model width <a class=\"anchor\" id=\"fwhm\"><a>\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the fitting algorithm.\n",
    "data = median_reinterpolation\n",
    "fit_method = fitting.LevMarLSQFitter()\n",
    "amplitude = numpy.max(data)\n",
    "    \n",
    "# Declare the type of model to fit.\n",
    "fit_model = models.Gaussian2D(amplitude, x_mean=new_center, y_mean=new_center)\n",
    "        \n",
    "# Generate the model array.            \n",
    "ximg, yimg = numpy.indices(data.shape)\n",
    "    \n",
    "# Fit the model to the data and evaluate.\n",
    "fit_result = fit_method(fit_model, ximg, yimg, data, maxiter=max_iterations)\n",
    "model = fit_result(ximg, yimg)\n",
    "residual = (data - model) \n",
    "    \n",
    "# Plot the data, model, and residuals side-by-side.\n",
    "figure, mysubplot = matplotlib.pyplot.subplots(1, 3, figsize=(11, 11))\n",
    "mysubplot[0].imshow(data, vmin=0.0, vmax=numpy.amax(data)/10.0, origin='lower')\n",
    "mysubplot[1].imshow(model, vmin=0.0, vmax=numpy.amax(model)/10.0, origin='lower')\n",
    "mysubplot[2].imshow(residual, vmin=0.0, vmax=numpy.amax(residual)/10.0, origin='lower')\n",
    "matplotlib.pyplot.tight_layout()\n",
    "print('\\n              DATA:                          MODEL:                           RESIDUAL:') \n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "print('Fit Parameters:\\n')\n",
    "print(fit_result.amplitude)\n",
    "print(fit_result.x_mean)\n",
    "print(fit_result.y_mean)\n",
    "print(fit_result.x_stddev)\n",
    "print(fit_result.y_stddev)\n",
    "print(fit_result.theta)\n",
    "\n",
    "psf_fwhm_pix = numpy.around(numpy.mean([fit_result.x_stddev.value, fit_result.y_stddev.value])*2.354, decimals=3)\n",
    "\n",
    "print('\\nThe PSF FWHM is', psf_fwhm_pix, 'pixels.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Data Products\n",
    "\n",
    "The code will output two PSF models. The first is a mean-stack of the subimages while the second is a median-stack. If *dual_psf = False* then the results will be output into *stellar* and *empirical* folders. If *dual_psf = True* then there will be sub-folders named \"inner\" and \"outer\" with the resulting model files.\n",
    "\n",
    "***\n",
    "\n",
    "# Troubleshooting <a class=\"anchor\" id=\"trouble\"><a>\n",
    "\n",
    " - **The code is taking a very long time to run, how can I speed it up?**\n",
    "      - The majority of computation time is spent in the Moffat/Gaussian profile fitting, so use *parallel_mode = True* with as many cores available for a significant performance boost. Also, if you cannot lower the grid resolution (set by *interp_grid_steps*), consider fitting fewer sources. If the stars are very symmetric, which may be the case with some UVIS images, consider using the peak locations (*use_peaks = True*) instead of fitting profiles.\n",
    "\n",
    "\n",
    " - **I'm using *psf_type = empirical* with a drizzle made by *wfc3tools* and the code cannot find the planted PSFs?**\n",
    " \n",
    "      - Go to this line: [*peaks_table = find_peaks(...)*](#import2) and modify the threshold value. In general this should be robust for most images. Set the threshold approximately equal to ~ 10-20% of the peak flux values in your drizzle or higher until it only locates the PSF peaks.\n",
    "      \n",
    "[Table of Contents](#tag0)      \n",
    "      \n",
    "***\n",
    "\n",
    "# Developer Notes <a class=\"anchor\" id=\"developer\"><a>\n",
    "\n",
    "**The following action items are planned for future releases:**\n",
    " - Have the code read-in a DS9 region file or weight map (rather than using a circle) for inner/outer regions.\n",
    " \n",
    " - Have the code overplot the selected stars on the mosaic for visual inspection and publication figures. \n",
    "  \n",
    " - Confirm the 'even' and 'odd' modes produce PSF models that are always centered on the output image grid.\n",
    " \n",
    " - Confirm the code works properly for drizzles produced using AstroDrizzle with the *build = True* option.\n",
    "   \n",
    " - Have the code determine the *find_peaks* threshold using *from astropy.stats import sigma_clipped_stats*.\n",
    " \n",
    " - Note that models run with read_positions = T/F have the same filename and will be over-written.\n",
    "\n",
    "[Table of Contents](#tag0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if speak == True:\n",
    "    \n",
    "    os.system(\"say 'your notebook has finished running.'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
